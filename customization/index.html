



<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      <meta http-equiv="x-ua-compatible" content="ie=edge">
      
        <meta name="description" content="Data Mining">
      
      
        <link rel="canonical" href="https://awlya12.github.io/DataMining_AulyaFridayanti_170441100017/customization/">
      
      
        <meta name="author" content="Aulya Fridayanti">
      
      
        <meta name="lang:clipboard.copy" content="Copy to clipboard">
      
        <meta name="lang:clipboard.copied" content="Copied to clipboard">
      
        <meta name="lang:search.language" content="en">
      
        <meta name="lang:search.pipeline.stopwords" content="True">
      
        <meta name="lang:search.pipeline.trimmer" content="True">
      
        <meta name="lang:search.result.none" content="No matching documents">
      
        <meta name="lang:search.result.one" content="1 matching document">
      
        <meta name="lang:search.result.other" content="# matching documents">
      
        <meta name="lang:search.tokenizer" content="[\s\-]+">
      
      <link rel="shortcut icon" href="../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.0.4, mkdocs-material-4.2.0">
    
    
      
        <title>Decision Tree - Aulya's Project</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/application.750b69bd.css">
      
        <link rel="stylesheet" href="../assets/stylesheets/application-palette.224b79ff.css">
      
      
        
        
        <meta name="theme-color" content="#3f51b5">
      
    
    
      <script src="../assets/javascripts/modernizr.74668098.js"></script>
    
    
      
        <link href="https://fonts.gstatic.com" rel="preconnect" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700|Roboto+Mono">
        <style>body,input{font-family:"Roboto","Helvetica Neue",Helvetica,Arial,sans-serif}code,kbd,pre{font-family:"Roboto Mono","Courier New",Courier,monospace}</style>
      
    
    <link rel="stylesheet" href="../assets/fonts/material-icons.css">
    
    
    
      
        
<script>
  window.ga = window.ga || function() {
    (ga.q = ga.q || []).push(arguments)
  }
  ga.l = +new Date
  /* Setup integration and send page view */
  ga("create", "None", "auto")
  ga("set", "anonymizeIp", true)
  ga("send", "pageview")
  /* Register handler to log search on blur */
  document.addEventListener("DOMContentLoaded", () => {
    if (document.forms.search) {
      var query = document.forms.search.query
      query.addEventListener("blur", function() {
        if (this.value) {
          var path = document.location.pathname;
          ga("send", "pageview", path + "?q=" + this.value)
        }
      })
    }
  })
</script>
<script async src="https://www.google-analytics.com/analytics.js"></script>
      
    
    
  </head>
  
    
    
    <body dir="ltr" data-md-color-primary="indigo" data-md-color-accent="indigo">
  
    <svg class="md-svg">
      <defs>
        
        
          <svg xmlns="http://www.w3.org/2000/svg" width="416" height="448"
    viewBox="0 0 416 448" id="__github">
  <path fill="currentColor" d="M160 304q0 10-3.125 20.5t-10.75 19-18.125
        8.5-18.125-8.5-10.75-19-3.125-20.5 3.125-20.5 10.75-19 18.125-8.5
        18.125 8.5 10.75 19 3.125 20.5zM320 304q0 10-3.125 20.5t-10.75
        19-18.125 8.5-18.125-8.5-10.75-19-3.125-20.5 3.125-20.5 10.75-19
        18.125-8.5 18.125 8.5 10.75 19 3.125 20.5zM360
        304q0-30-17.25-51t-46.75-21q-10.25 0-48.75 5.25-17.75 2.75-39.25
        2.75t-39.25-2.75q-38-5.25-48.75-5.25-29.5 0-46.75 21t-17.25 51q0 22 8
        38.375t20.25 25.75 30.5 15 35 7.375 37.25 1.75h42q20.5 0
        37.25-1.75t35-7.375 30.5-15 20.25-25.75 8-38.375zM416 260q0 51.75-15.25
        82.75-9.5 19.25-26.375 33.25t-35.25 21.5-42.5 11.875-42.875 5.5-41.75
        1.125q-19.5 0-35.5-0.75t-36.875-3.125-38.125-7.5-34.25-12.875-30.25-20.25-21.5-28.75q-15.5-30.75-15.5-82.75
        0-59.25 34-99-6.75-20.5-6.75-42.5 0-29 12.75-54.5 27 0 47.5 9.875t47.25
        30.875q36.75-8.75 77.25-8.75 37 0 70 8 26.25-20.5
        46.75-30.25t47.25-9.75q12.75 25.5 12.75 54.5 0 21.75-6.75 42 34 40 34
        99.5z" />
</svg>
        
      </defs>
    </svg>
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" data-md-component="overlay" for="__drawer"></label>
    
      <a href="#decision-tree-pohon-keputusan" tabindex="1" class="md-skip">
        Skip to content
      </a>
    
    
      <header class="md-header" data-md-component="header">
  <nav class="md-header-nav md-grid">
    <div class="md-flex">
      <div class="md-flex__cell md-flex__cell--shrink">
        <a href="https://awlya12.github.io/DataMining_AulyaFridayanti_170441100017/" title="Aulya's Project" class="md-header-nav__button md-logo">
          
            <i class="md-icon"></i>
          
        </a>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        <label class="md-icon md-icon--menu md-header-nav__button" for="__drawer"></label>
      </div>
      <div class="md-flex__cell md-flex__cell--stretch">
        <div class="md-flex__ellipsis md-header-nav__title" data-md-component="title">
          
            <span class="md-header-nav__topic">
              Aulya's Project
            </span>
            <span class="md-header-nav__topic">
              Decision Tree
            </span>
          
        </div>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        
          <label class="md-icon md-icon--search md-header-nav__button" for="__search"></label>
          
<div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="query" data-md-state="active">
      <label class="md-icon md-search__icon" for="__search"></label>
      <button type="reset" class="md-icon md-search__icon" data-md-component="reset" tabindex="-1">
        &#xE5CD;
      </button>
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="result">
          <div class="md-search-result__meta">
            Type to start searching
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
        
      </div>
      
        <div class="md-flex__cell md-flex__cell--shrink">
          <div class="md-header-nav__source">
            


  

<a href="https://github.com/Awlya12/DataMining_AulyaFridayanti_170441100017" title="Go to repository" class="md-source" data-md-source="github">
  
    <div class="md-source__icon">
      <svg viewBox="0 0 24 24" width="24" height="24">
        <use xlink:href="#__github" width="24" height="24"></use>
      </svg>
    </div>
  
  <div class="md-source__repository">
    My Project
  </div>
</a>
          </div>
        </div>
      
    </div>
  </nav>
</header>
    
    <div class="md-container">
      
        
      
      
        

<nav class="md-tabs" data-md-component="tabs">
  <div class="md-tabs__inner md-grid">
    <ul class="md-tabs__list">
      
        
  <li class="md-tabs__item">
    
      <a href=".." title="Home" class="md-tabs__link md-tabs__link--active">
        Home
      </a>
    
  </li>

      
        
      
        
      
        
      
    </ul>
  </div>
</nav>
      
      <main class="md-main">
        <div class="md-main__inner md-grid" data-md-component="container">
          
            
              <div class="md-sidebar md-sidebar--primary" data-md-component="navigation">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    <nav class="md-nav md-nav--primary" data-md-level="0">
  <label class="md-nav__title md-nav__title--site" for="__drawer">
    <a href="https://awlya12.github.io/DataMining_AulyaFridayanti_170441100017/" title="Aulya's Project" class="md-nav__button md-logo">
      
        <i class="md-icon"></i>
      
    </a>
    Aulya's Project
  </label>
  
    <div class="md-nav__source">
      


  

<a href="https://github.com/Awlya12/DataMining_AulyaFridayanti_170441100017" title="Go to repository" class="md-source" data-md-source="github">
  
    <div class="md-source__icon">
      <svg viewBox="0 0 24 24" width="24" height="24">
        <use xlink:href="#__github" width="24" height="24"></use>
      </svg>
    </div>
  
  <div class="md-source__repository">
    My Project
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      


  <li class="md-nav__item">
    <a href=".." title="Home" class="md-nav__link">
      Home
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../getting-started/" title="K-Means Clustering" class="md-nav__link">
      K-Means Clustering
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../specimen/" title="K-Nearest Neighbor" class="md-nav__link">
      K-Nearest Neighbor
    </a>
  </li>

    
      
      
      

  


  <li class="md-nav__item md-nav__item--active">
    
    <input class="md-toggle md-nav__toggle" data-md-toggle="toc" type="checkbox" id="__toc">
    
      
    
    
      <label class="md-nav__link md-nav__link--active" for="__toc">
        Decision Tree
      </label>
    
    <a href="./" title="Decision Tree" class="md-nav__link md-nav__link--active">
      Decision Tree
    </a>
    
      
<nav class="md-nav md-nav--secondary">
  
  
    
  
  
    <label class="md-nav__title" for="__toc">Table of contents</label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#decision-tree" title="Decision Tree" class="md-nav__link">
    Decision Tree
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#perhitungan-algoritma-decision-tree" title="Perhitungan Algoritma Decision Tree" class="md-nav__link">
    Perhitungan Algoritma Decision Tree
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#klasifikasi-dengan-menggunakan-algoritma-id3" title="Klasifikasi dengan menggunakan algoritma ID3 ." class="md-nav__link">
    Klasifikasi dengan menggunakan algoritma ID3 .
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
      
      
      
      
    </ul>
  
</nav>
    
  </li>

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              <div class="md-sidebar md-sidebar--secondary" data-md-component="toc">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    
<nav class="md-nav md-nav--secondary">
  
  
    
  
  
    <label class="md-nav__title" for="__toc">Table of contents</label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#decision-tree" title="Decision Tree" class="md-nav__link">
    Decision Tree
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#perhitungan-algoritma-decision-tree" title="Perhitungan Algoritma Decision Tree" class="md-nav__link">
    Perhitungan Algoritma Decision Tree
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#klasifikasi-dengan-menggunakan-algoritma-id3" title="Klasifikasi dengan menggunakan algoritma ID3 ." class="md-nav__link">
    Klasifikasi dengan menggunakan algoritma ID3 .
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
      
      
      
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content">
            <article class="md-content__inner md-typeset">
              
                
                
                <h1 id="decision-tree-pohon-keputusan"><strong>DECISION TREE ( Pohon Keputusan)</strong><a class="headerlink" href="#decision-tree-pohon-keputusan" title="Permanent link">&para;</a></h1>
<div class="toc">
<ul>
<li><a href="#decision-tree-pohon-keputusan">DECISION TREE ( Pohon Keputusan)</a><ul>
<li><a href="#decision-tree">Decision Tree</a></li>
<li><a href="#perhitungan-algoritma-decision-tree">Perhitungan Algoritma Decision Tree</a><ul>
<li><a href="#klasifikasi-dengan-menggunakan-algoritma-id3">Klasifikasi dengan menggunakan algoritma ID3 .</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#implementasi">Implementasi</a><ul>
<li><a href="#library-yang-diperlukan">Library yang diperlukan</a></li>
</ul>
</li>
<li><a href="#referensi">Referensi</a></li>
</ul>
</div>
<h2 id="decision-tree"><strong>Decision Tree</strong><a class="headerlink" href="#decision-tree" title="Permanent link">&para;</a></h2>
<p>​   Pohon keputusan dalam aturan keputusan (<em>decision rule</em>) merupakan metodologi data mining yang banyak diterapkan sebagai solusi untuk klasifikasi. <em>Decision tree</em> merupakan suatu metode klasifikasi yang menggunakan struktur pohon, dimana setiap <em>node</em> merepresentasikan atribut dan cabangnya merepresentasikan nilai dari atribut, sedangkan daunnya digunakan untuk merepresentasikan kelas. <em>Node</em> teratas dari <em>decision tree</em> ini disebut dengan <em>root</em>.</p>
<p>​   Breiman <em>et al</em>. (1984) menyatakan bahwa metode ini merupakan metode yang sangat populer untuk digunakan karena hasil dari model yang terbentuk mudah untuk dipahami. Dinamakan pohon keputusan karena aturan yang terbentuk mirip dengan bentuk pohon. Pohon terbentuk dari proses pemilahan rekursif biner pada suatu gugus data sehingga nilai variabel respon pada setiap gugus data hasil pemilahan akan lebih homogen. Pada pohon keputusan terdapat tiga jenis <em>node</em>, antara lain :</p>
<p><strong>1. Akar</strong>
Merupakan <em>node</em> teratas, pada <em>node</em> ini tidak ada input dan dapat tidak mempunyai output atau dapat mempunyai output lebih dari satu.
<strong>2. Internal node**Merupakan <em>node</em> percabangan, pada <em>node</em> ini hanya terdapat satu input dan mempunyai output minimal dua.
**3. Daun</strong>
Merupakan <em>node</em> akhir atau terminal <em>node</em>, pada <em>node</em> ini hanya terdapat satu input dan tidak mempunyai output (simpul terminal).</p>
<p>Sebagai contoh suatu pohon disusun oleh simpul t1, t2, …, t4 dengan rincian terdapat 3 daun, 1 akar, dan 1 <em>internal</em> <em>node</em>. Setiap pemilah (<em>split</em>) memilah simpul nonterminal menjadi dua simpul yang saling lepas. Hasil prediksi respon suatu amatan terdapat pada simpul terminal (daun).</p>
<p><img alt="" src="../assets/images/tree.png" /></p>
<p>Konsep dari pohon keputusan adalah mengubah data menjadi pohon keputusan dan aturan-aturan keputusan. Pohon keputusan merupakan himpunan aturan <em>if — then</em>, dimana setiap <em>path</em> dalam pohon dihubungkan dengan sebuah aturan dimana premis terdiri atas sekumpulan <em>node</em> yang ditemui dan kesimpulan dari aturan terdiri atas kelas yang dihubungkan dengan daun dari <em>path</em>. Pembentukan pohon keputusan terdiri dari beberapa tahap :</p>
<p><strong>1. Konstruksi pohon</strong> diawali dengan pembentukan akar (terletak paling atas). Kemudian data dibagi berdasarkan atribut-atribut yang cocok untuk dijadikan daun.</p>
<p><strong>2. Pemangkasan pohon (tree pruning)</strong> yaitu mengidentifikasikan dan membuang cabang yang tidak diperlukan pada pohon yang telah terbentuk. Hal ini dikarenakan pohon keputusan yang dikontruksi dapat berukuran besar, maka dapat disederhanakan dengan melakukan pemangkasan berdasarkan nilai kepercayaan (<em>confident level</em>). Pemangkasan pohon dilakukan selain untuk pengurangan ukuran pohon juga bertujuan untuk mengurangi tingkat kesalahan prediksi pada kasus baru dari hasil pemecahan yang dilakukan dengan <em>divide and conquer</em>. <em>Pruning</em> ada dua pendekatan yaitu :</p>
<p><strong>a. Pre-pruning</strong> yaitu menghentikan pembangunan suatu <em>subtree</em> lebih awal (dengan memutuskan untuk tidak lebih jauh mempartisi data training). Saat seketika berhenti, maka <em>node</em> berubah menjadi <em>leaf</em> (node akhir). <em>Node</em> akhir ini menjadi kelas yang paling sering muncul di antara subset sampel.</p>
<p><strong>b. Post-pruning</strong> yaitu menyederhanakan <em>tree</em> dengan cara membuang beberapa cabang <em>subtree</em> setelah <em>tree</em> selesai dibangun. <em>Node</em> yang jarang dipotong akan menjadi <em>leaf</em> (node akhir) dengan kelas yang paling sering muncul.</p>
<p><strong>3. Pembentukan aturan keputusan</strong> yaitu membuat aturan keputusan dari pohon yang telah dibentuk. Aturan tersebut dapat dalam bentuk <em>if — then</em> diturunkan dari pohon keputusan dengan melakukan penelusuran dari akar sampai ke daun. Untuk setiap simpul dan percabangannya akan diberikan di <em>if</em>, sedangkan nilai pada daun akan ditulis di <em>then</em>. Setelah semua aturan dibuat maka aturan dapat disederhanakan atau digabung.</p>
<p><em>Decision tree</em> adalah suatu model klasifikasi yang paling populer karena mudah diinterpretasikan oleh manusia. Banyak algoritma yang dapat digunakan dalam pembentukan pohon keputusan seperti ID3, C4.5, CART, dan GUIDE. Algoritma <em>decision tree</em> banyak digunakan dalam proses data mining karena memiliki beberapa <strong>kelebihan</strong> :</p>
<p>1. Mudah mengintegrasikan dengan sistem basis data.
2. Memiliki ketelitian yang baik.
3. Dapat menemukan gabungan tak terduga dari suatu data.
4. Daerah pengambilan keputusan yang sebelumnya kompleks dan sangat global dapat diubah menjadi lebih sederhana dan spesifik.
5. Dapat melakukan eliminasi untuk perhitungan-perhitungan yang tidak diperlukan. Karena ketika menggunakan metode ini maka sampel hanya diuji berdasarkan kriteria atau kelas tertentu.
6. Fleksibel untuk memilih fitur dari internal node yang berbeda, fitur yang terpilih akan membedakan suatu kriteria dibandingkan kriteria yang lain dalam node yang sama.</p>
<p><strong>Kekurangan</strong> pohon keputusan adalah.</p>
<ol>
<li>Terjadi overlap terutama ketika kelas-kelas dan kriteria yang digunakan jumlahnya sangat banyak. Hal tersebut juga dapat menyebabkan meningkatnya waktu pengambilan keputusan dan jumlah memori yang diperlukan.</li>
<li>Pengakumulasian jumlah error dari setiap tingkat dalam sebuah pohon keputusan yang besar.</li>
<li>Kesulitan dalam mendesain pohon keputusan yang optimal.</li>
<li>Hasil kualitas keputusan yang didapatkan dari metode pohon keputusan sangat bergantung pada bagaimana pohon tersebut didesain.</li>
</ol>
<blockquote>
<p><strong>Oke jadi bagaimana membangun ini ??</strong></p>
</blockquote>
<h2 id="perhitungan-algoritma-decision-tree"><strong>Perhitungan Algoritma Decision Tree</strong><a class="headerlink" href="#perhitungan-algoritma-decision-tree" title="Permanent link">&para;</a></h2>
<p>Ada beberapa algoritma di sana untuk membangun pohon keputusan, kita hanya membicarakan beberapa saja</p>
<ol>
<li>CART (Klasifikasi dan Pohon Regresi) → menggunakan <strong>Indeks Gini (Klasifikasi)</strong> sebagai metrik.</li>
<li>ID3 (Iterative Dichotomiser 3) → menggunakan <strong>fungsi Entropi</strong> dan <strong>Penghasilan</strong> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;hl=id&amp;prev=search&amp;rurl=translate.google.com&amp;sl=en&amp;sp=nmt4&amp;u=https://en.wikipedia.org/wiki/Information_gain_in_decision_trees&amp;xid=17259,15700023,15700186,15700191,15700253,15700256,15700259&amp;usg=ALkJrhhCkNgmNNUoBxBmPRbprpQGuhBbeQ"><strong>informasi</strong></a> sebagai metrik.</li>
</ol>
<p>Mari kita bangun pohon keputusan untuk masalah klasifikasi menggunakan algoritma di atas,</p>
<h3 id="klasifikasi-dengan-menggunakan-algoritma-id3"><strong>Klasifikasi dengan menggunakan algoritma ID3 .</strong><a class="headerlink" href="#klasifikasi-dengan-menggunakan-algoritma-id3" title="Permanent link">&para;</a></h3>
<p>Mari kita ambil dataset terkenal di dunia pembelajaran mesin yaitu dataset cuaca (bermain game Y atau N berdasarkan kondisi cuaca).</p>
<p><img alt="img" src="../assets/images/t1.jpeg" /></p>
<p>Disini terdapat empat nilai X (pandangan, temp, kelembaban dan berangin) menjadi kategoris dan satu nilai y (bermain Y atau N) juga menjadi kategoris.</p>
<p>jadi hanya perlu belajar pemetaan (apa yang selalu dipelajari dengan mesin) antara X dan y.</p>
<p>Ini adalah masalah klasifikasi biner, mari kita bangun pohon menggunakan algoritma <strong>ID3</strong></p>
<p>Untuk membuat pohon, kita perlu memiliki simpul akar terlebih dahulu dan kita tahu bahwa simpul adalah fitur / atribut (pandangan, temp, kelembaban dan berangin),</p>
<blockquote>
<p>jadi mana yang harus kita pilih dulu ??</p>
</blockquote>
<p><strong>Jawab</strong> : tentukan atribut yang paling mengklasifikasikan data pelatihan;gunakan atribut ini di akar pohon. Ulangi proses ini di untuk setiap cabang.</p>
<p>Ini berarti kami melakukan pencarian top-down, serakah melalui ruang pohon keputusan yang memungkinkan.</p>
<blockquote>
<p>oke jadi bagaimana kita memilih atribut terbaik?</p>
</blockquote>
<p><strong>Jawab</strong> : gunakan atribut dengan <strong>perolehan informasi</strong> tertinggi di <strong>ID3</strong></p>
<p><em>Untuk mendefinisikan perolehan informasi secara tepat, kita mulai dengan mendefinisikan ukuran yang biasa digunakan dalam teori informasi, yang disebut</em> <strong>entropi</strong> <em>yang mencirikan kemurnian (im) dari kumpulan contoh yang sewenang-wenang. ”</em></p>
<p><img alt="img" src="../assets/images/t2.jpeg" /></p>
<p>Untuk masalah klasifikasi biner</p>
<ul>
<li>Jika semua contoh positif atau semua negatif maka entropi akan menjadi <strong>nol</strong> yaitu, rendah.</li>
<li>Jika setengah dari contoh adalah kelas positif dan setengah dari kelas negatif maka entropi adalah <strong>satu</strong> yaitu, tinggi.</li>
</ul>
<p><img alt="img" src="../assets/images/t3.jpeg" /></p>
<p>Oke mari terapkan metrik ini ke dataset kami untuk membagi data (mendapatkan simpul root)</p>
<p>Langkah - langkah:</p>
<div class="codehilite"><pre><span></span>  1. menghitung entropi untuk kumpulan data 
  2. untuk setiap atribut / fitur: 
  1. menghitung entropi untuk semua nilai kategorikal 
  2.mengambil entropi informasi rata-rata untuk atribut saat ini 
  3. menghitung keuntungan untuk atribut saat ini 
  3. pilih atribut gain tertinggi. 
  4. Ulangi sampai kita mendapatkan pohon yang kita inginkan. 
</pre></div>

<blockquote>
<p>Hitung entropi untuk kumpulan data cuaca:</p>
</blockquote>
<p><img alt="img" src="../assets/images/t4.jpeg" /></p>
<blockquote>
<p>Untuk setiap fitur hitung entropi dan perolehan informasi</p>
</blockquote>
<p><img alt="img" src="../assets/images/t5.jpeg" /></p>
<p>Kesamaan dapat di hitung untuk dua atribut lainnya (Kelembaban dan Temp).</p>
<blockquote>
<p>Pilih atribut gain tertinggi.</p>
</blockquote>
<p><img alt="img" src="../assets/images/t6.jpeg" /></p>
<p>Jadi root node adalah <strong>Outlook.</strong></p>
<p><img alt="img" src="../assets/images/t7.jpeg" /></p>
<blockquote>
<p>Ulangi hal yang sama untuk sub-pohon sampai mendapatkan pohonnya.</p>
</blockquote>
<p><img alt="img" src="../assets/images/t8.jpeg" /></p>
<p>Sehingga mendapatkan pohon seperti itu.</p>
<p><img alt="img" src="../assets/images/t9.jpeg" /></p>
<h1 id="implementasi">Implementasi<a class="headerlink" href="#implementasi" title="Permanent link">&para;</a></h1>
<h3 id="library-yang-diperlukan"><strong>Library yang diperlukan</strong><a class="headerlink" href="#library-yang-diperlukan" title="Permanent link">&para;</a></h3>
<ul>
<li>Panda 0.20.3</li>
<li>IPython</li>
<li>Sklearn 0.19.1</li>
<li>pydotplus</li>
<li>graphviz</li>
<li>Jupyter Notebook —-&gt; gua pake ini untuk IDE nya</li>
</ul>
<p>Untuk keseluruhan code nya dapat dilihat di bagian paling bawah tulisan ini</p>
<div class="codehilite"><pre><span></span><span class="c1"># Panda library untuk membaca file csv</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="kn">as</span> <span class="nn">pd</span>
<span class="n">DT_data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;credit.csv&quot;</span><span class="p">,</span><span class="n">index_col</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">DT_data</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
<span class="n">DT_data</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">DT_data</span><span class="p">[</span><span class="s1">&#39;RESPONSE&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
<span class="n">DT_data</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span>
</pre></div>

<p><img alt="" src="../assets/images/im1.JPG" /></p>
<div class="codehilite"><pre><span></span><span class="c1"># Train / Test split</span>

<span class="n">DT_train</span><span class="o">=</span><span class="n">DT_data</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">700</span><span class="p">]</span>
<span class="n">DT_test</span><span class="o">=</span><span class="n">DT_data</span><span class="p">[</span><span class="mi">700</span><span class="p">:</span><span class="mi">1000</span><span class="p">]</span>
<span class="sd">&#39;&#39;&#39;</span>
<span class="sd">X = DT_data.values[:, 1:31]</span>
<span class="sd">Y = DT_data.values[:, 31]</span>
<span class="sd">&#39;&#39;&#39;</span>

<span class="n">x_vars</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;CHK_ACCT&#39;</span><span class="p">,</span> <span class="s1">&#39;DURATION&#39;</span><span class="p">,</span> <span class="s1">&#39;HISTORY&#39;</span><span class="p">,</span> <span class="s1">&#39;NEW_CAR&#39;</span><span class="p">,</span> <span class="s1">&#39;USED_CAR&#39;</span><span class="p">,</span> <span class="s1">&#39;FURNITURE&#39;</span><span class="p">,</span> <span class="s1">&#39;RADIO/TV&#39;</span><span class="p">,</span> <span class="s1">&#39;EDUCATION&#39;</span><span class="p">,</span> <span class="s1">&#39;RETRAINING&#39;</span><span class="p">,</span> <span class="s1">&#39;AMOUNT&#39;</span><span class="p">,</span> <span class="s1">&#39;SAV_ACCT&#39;</span><span class="p">,</span> <span class="s1">&#39;EMPLOYMENT&#39;</span><span class="p">,</span> <span class="s1">&#39;INSTALL_RATE&#39;</span><span class="p">,</span> <span class="s1">&#39;MALE_DIV&#39;</span><span class="p">,</span> <span class="s1">&#39;MALE_SINGLE&#39;</span><span class="p">,</span> <span class="s1">&#39;MALE_MAR_or_WID&#39;</span><span class="p">,</span> <span class="s1">&#39;CO-APPLICANT&#39;</span><span class="p">,</span> <span class="s1">&#39;GUARANTOR&#39;</span><span class="p">,</span> <span class="s1">&#39;PRESENT_RESIDENT&#39;</span><span class="p">,</span> <span class="s1">&#39;REAL_ESTATE&#39;</span><span class="p">,</span> <span class="s1">&#39;PROP_UNKN_NONE&#39;</span><span class="p">,</span> <span class="s1">&#39;AGE&#39;</span><span class="p">,</span> <span class="s1">&#39;OTHER_INSTALL&#39;</span><span class="p">,</span> <span class="s1">&#39;RENT&#39;</span><span class="p">,</span> <span class="s1">&#39;OWN_RES&#39;</span><span class="p">,</span> <span class="s1">&#39;NUM_CREDITS&#39;</span><span class="p">,</span> <span class="s1">&#39;JOB&#39;</span><span class="p">,</span> <span class="s1">&#39;NUM_DEPENDENTS&#39;</span><span class="p">,</span> <span class="s1">&#39;TELEPHONE&#39;</span><span class="p">,</span> <span class="s1">&#39;FOREIGN&#39;</span><span class="p">]</span>
</pre></div>

<div class="codehilite"><pre><span></span><span class="c1"># Proses mengembangkan decision tree</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">tree</span>

<span class="n">cl_tree</span> <span class="o">=</span> <span class="n">tree</span><span class="o">.</span><span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">criterion</span><span class="o">=</span><span class="s1">&#39;entropy&#39;</span><span class="p">,</span>
                                         <span class="n">random_state</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span>
                               <span class="n">max_depth</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">min_samples_leaf</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>



<span class="n">cl_tree</span><span class="o">=</span><span class="n">cl_tree</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">DT_train</span><span class="p">[</span><span class="n">x_vars</span><span class="p">],</span> <span class="n">DT_train</span><span class="p">[</span><span class="s1">&#39;RESPONSE&#39;</span><span class="p">])</span>

<span class="n">pred</span><span class="o">=</span><span class="n">cl_tree</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">DT_test</span><span class="p">[</span><span class="n">x_vars</span><span class="p">])</span>
<span class="n">pd</span><span class="o">.</span><span class="n">crosstab</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span><span class="n">DT_test</span><span class="p">[</span><span class="s1">&#39;RESPONSE&#39;</span><span class="p">])</span>



<span class="kn">from</span> <span class="nn">sklearn.externals.six</span> <span class="kn">import</span> <span class="n">StringIO</span>  
<span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">Image</span>  
<span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">export_graphviz</span>
<span class="kn">import</span> <span class="nn">pydotplus</span>
<span class="n">dot_data</span> <span class="o">=</span> <span class="n">StringIO</span><span class="p">()</span>
<span class="n">export_graphviz</span><span class="p">(</span><span class="n">cl_tree</span><span class="p">,</span> <span class="n">out_file</span><span class="o">=</span><span class="n">dot_data</span><span class="p">,</span> <span class="n">feature_names</span><span class="o">=</span><span class="n">x_vars</span><span class="p">,</span> 
                <span class="n">filled</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">rounded</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
                <span class="n">special_characters</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="n">graph</span> <span class="o">=</span> <span class="n">pydotplus</span><span class="o">.</span><span class="n">graph_from_dot_data</span><span class="p">(</span><span class="n">dot_data</span><span class="o">.</span><span class="n">getvalue</span><span class="p">())</span>  

<span class="c1"># untuk mengeluarkan gambar hasil decision tree</span>
<span class="kn">import</span> <span class="nn">graphviz</span> 
<span class="n">Image</span><span class="p">(</span><span class="n">graph</span><span class="o">.</span><span class="n">create_png</span><span class="p">())</span>
</pre></div>

<p>Maka hasil dari kode diatas adalah :</p>
<p><img alt="" src="../assets/images/aw.png" /></p>
<h1 id="referensi">Referensi<a class="headerlink" href="#referensi" title="Permanent link">&para;</a></h1>
<ol>
<li>
<p><a href="https://belajarpython345774210.wordpress.com/2018/02/16/machine-learning-decision-trees-python-pemula/">https://belajarpython345774210.wordpress.com/2018/02/16/machine-learning-decision-trees-python-pemula/</a> </p>
</li>
<li>
<p><a href="https://medium.com/deep-math-machine-learning-ai/chapter-4-decision-trees-algorithms-b93975f7a1f1">https://medium.com/deep-math-machine-learning-ai/chapter-4-decision-trees-algorithms-b93975f7a1f1</a> </p>
</li>
<li>
<p><a href="https://en.wikipedia.org/wiki/Decision_tree">https://en.wikipedia.org/wiki/Decision_tree</a> </p>
</li>
<li>
<p><a href="https://yudiagusta.wordpress.com/2008/07/16/decision-trees/">https://yudiagusta.wordpress.com/2008/07/16/decision-trees/</a></p>
</li>
</ol>
                
                  
                
              
              
                


              
            </article>
          </div>
        </div>
      </main>
      
        
<footer class="md-footer">
  
    <div class="md-footer-nav">
      <nav class="md-footer-nav__inner md-grid">
        
          <a href="../specimen/" title="K-Nearest Neighbor" class="md-flex md-footer-nav__link md-footer-nav__link--prev" rel="prev">
            <div class="md-flex__cell md-flex__cell--shrink">
              <i class="md-icon md-icon--arrow-back md-footer-nav__button"></i>
            </div>
            <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
              <span class="md-flex__ellipsis">
                <span class="md-footer-nav__direction">
                  Previous
                </span>
                K-Nearest Neighbor
              </span>
            </div>
          </a>
        
        
      </nav>
    </div>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-footer-copyright">
        
          <div class="md-footer-copyright__highlight">
            Copyright &copy; 2019 Aulya Fridayanti
          </div>
        
        powered by
        <a href="https://www.mkdocs.org">MkDocs</a>
        and
        <a href="https://squidfunk.github.io/mkdocs-material/">
          Material for MkDocs</a>
      </div>
      
  <div class="md-footer-social">
    <link rel="stylesheet" href="../assets/fonts/font-awesome.css">
    
      <a href="https://github.com/Awlya12" class="md-footer-social__link fa fa-github-alt"></a>
    
      <a href="https://twitter.com/AULYAFRDY" class="md-footer-social__link fa fa-twitter"></a>
    
      <a href="https://linkedin.com/in/Aulyafrd01" class="md-footer-social__link fa fa-linkedin"></a>
    
  </div>

    </div>
  </div>
</footer>
      
    </div>
    
      <script src="../assets/javascripts/application.8c0d971c.js"></script>
      
      <script>app.initialize({version:"1.0.4",url:{base:".."}})</script>
      
    
  </body>
</html>